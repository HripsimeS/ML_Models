{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('Datasets/Fashion_MNIST/X_train.npy')\n",
    "X_test = np.load('Datasets/Fashion_MNIST/X_test.npy')\n",
    "y_train = np.load('Datasets/Fashion_MNIST/y_train.npy')\n",
    "y_test = np.load('Datasets/Fashion_MNIST/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encoder.transform(y_train.reshape(-1, 1))\n",
    "y_test = encoder.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(X, y, size):\n",
    "    m = X.shape[0]\n",
    "    index = np.random.permutation(np.arange(m))\n",
    "    for i in range(m//size):\n",
    "        batch_i = index[i*size: i*size+size]\n",
    "        yield X[batch_i], y[batch_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(X, units, activation=None, kernel_initializer=None, name=None):\n",
    "    with tf.name_scope(f'dense/{name}'):\n",
    "        \n",
    "        if kernel_initializer:\n",
    "            initializer = kernel_initializer()\n",
    "        else:\n",
    "            initializer = tf.random_normal_initializer()\n",
    "            \n",
    "        W = tf.Variable(initializer([X.shape[1].value, units]), name='W')\n",
    "        b = tf.Variable(tf.zeros([units]), name='b')\n",
    "        Z = tf.add(tf.matmul(X, W), b)\n",
    "        \n",
    "        if activation:\n",
    "            A = activation(Z)\n",
    "        else:\n",
    "            A = Z\n",
    "            \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(X, y, layers, activation, kernel_initializer):\n",
    "    current_state = X\n",
    "    for i, layer in enumerate(layers):\n",
    "        current_state = dense(current_state, layer, activation, kernel_initializer, name=f\"layer_{i+1}\")\n",
    "    output = dense(current_state, y.shape[1].value, kernel_initializer=kernel_initializer, name=f\"output\" )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X_train, y_train, layers, learning_rate, epochs, batch_size, X_test, y_test, print_acc=False):\n",
    "    \n",
    "    n_features = X_train.shape[1]\n",
    "    n_labels = y_train.shape[1]\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_features], name='features')\n",
    "    y = tf.placeholder(tf.float32, shape=[None, n_labels], name='labels')\n",
    "    \n",
    "    output = dnn_model(X, y, layers, tf.tanh, tf.contrib.layers.xavier_initializer)\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(output,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=output)\n",
    "    cost = tf.reduce_mean(loss)\n",
    "\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=LR).minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            for i, (X_batch, y_batch) in enumerate(get_next_batch(X_train, y_train, Batch_size)):\n",
    "                _, c, train_acc = sess.run([train_op, cost, accuracy], {X: X_batch, y: y_batch})\n",
    "\n",
    "            if print_acc and epoch%10 == 0:\n",
    "                test_loss, test_acc = sess.run([cost, accuracy], {X: X_test, y: y_test})\n",
    "                print(\"Epoch:\", np.round(epoch,4),\n",
    "                      \"Train Loss:\", np.round(c, 4),\n",
    "                      \"Train accuracy:\", np.round(train_acc, 4),\n",
    "                      \"Test Loss:\", np.round(test_loss, 4),\n",
    "                      \"Test accuracy:\", np.round(test_acc,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 512\n",
    "LR = 0.0005\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layers = [256, 128, 64, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.5961 Train accuracy: 0.791 Test Loss: 0.5735 Test accuracy: 0.7911\n",
      "Epoch: 20 Train Loss: 0.5421 Train accuracy: 0.7969 Test Loss: 0.5689 Test accuracy: 0.7898\n",
      "Epoch: 30 Train Loss: 0.3898 Train accuracy: 0.8496 Test Loss: 0.5069 Test accuracy: 0.8143\n",
      "Epoch: 40 Train Loss: 0.4847 Train accuracy: 0.8125 Test Loss: 0.5158 Test accuracy: 0.805\n",
      "Epoch: 50 Train Loss: 0.4508 Train accuracy: 0.8262 Test Loss: 0.4969 Test accuracy: 0.8112\n",
      "Epoch: 60 Train Loss: 0.5297 Train accuracy: 0.8027 Test Loss: 0.5029 Test accuracy: 0.8125\n",
      "Epoch: 70 Train Loss: 0.5385 Train accuracy: 0.8047 Test Loss: 0.5005 Test accuracy: 0.8109\n",
      "Epoch: 80 Train Loss: 0.4435 Train accuracy: 0.8477 Test Loss: 0.4808 Test accuracy: 0.8211\n",
      "Epoch: 90 Train Loss: 0.4579 Train accuracy: 0.8281 Test Loss: 0.4643 Test accuracy: 0.8305\n",
      "Epoch: 100 Train Loss: 0.417 Train accuracy: 0.8242 Test Loss: 0.4469 Test accuracy: 0.8371\n"
     ]
    }
   ],
   "source": [
    "optimize(X_train, y_train, Layers, learning_rate=LR, epochs=epochs, batch_size=Batch_size, \n",
    "         X_test=X_test, y_test=y_test, print_acc=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

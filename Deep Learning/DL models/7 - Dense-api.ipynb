{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('Datasets/Fashion_MNIST/X_train.npy')\n",
    "X_test = np.load('Datasets/Fashion_MNIST/X_test.npy')\n",
    "y_train = np.load('Datasets/Fashion_MNIST/y_train.npy')\n",
    "y_test = np.load('Datasets/Fashion_MNIST/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(X, y, size):\n",
    "    m = X.shape[0]\n",
    "    index = np.random.permutation(np.arange(m))\n",
    "    for i in range(m//size):\n",
    "        batch_i = index[i*size: i*size+size]\n",
    "        yield X[batch_i], y[batch_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encoder.transform(y_train.reshape(-1, 1))\n",
    "y_test = encoder.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn(X, output_dim, layers, drop_rate, reuse, is_training):\n",
    "    with tf.variable_scope('DenselyConnected', reuse=reuse):\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=regularization_rate)\n",
    "        current_layer = X\n",
    "        for units in layers:\n",
    "            l = tf.layers.dense(current_layer,\n",
    "                                units,\n",
    "                                activation=tf.nn.tanh,\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                kernel_regularizer=regularizer)\n",
    "            \n",
    "            current_layer = tf.layers.dropout(l, rate=drop_rate, training=is_training)\n",
    "        \n",
    "        output = tf.layers.dense(current_layer, output_dim)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, y, layers, learning_rate, drop_rate):\n",
    "    train_logits = dnn(X, y.shape[1].value, layers, drop_rate, reuse=False, is_training=True)\n",
    "    test_logits = dnn(X, y.shape[1].value, layers, drop_rate, reuse=True, is_training=False)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=train_logits, labels=y))\n",
    "    loss += tf.losses.get_regularization_loss('DenselyConnected')\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "\n",
    "    \n",
    "    train_pred = tf.equal(tf.argmax(train_logits,1), tf.argmax(y,1))\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(train_pred,tf.float32))\n",
    "    \n",
    "    test_pred = tf.equal(tf.argmax(test_logits,1), tf.argmax(y,1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(test_pred,tf.float32))\n",
    "    return train_op, loss, train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "n_labels = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 256\n",
    "LR = 0.0005\n",
    "epochs = 100\n",
    "drop_rate = 0.0\n",
    "regularization_rate = 0.0\n",
    "Layers = [256, 128, 64, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "Epoch: 10  Loss: 0.67562664  Train accuracy: 0.734375  Test accuracy: 0.796875\n",
      "Epoch: 20  Loss: 0.44630224  Train accuracy: 0.84765625  Test accuracy: 0.796875\n",
      "Epoch: 30  Loss: 0.5172331  Train accuracy: 0.8203125  Test accuracy: 0.80859375\n",
      "Epoch: 40  Loss: 0.49093974  Train accuracy: 0.80078125  Test accuracy: 0.81640625\n",
      "Epoch: 50  Loss: 0.557464  Train accuracy: 0.79296875  Test accuracy: 0.77734375\n",
      "Epoch: 60  Loss: 0.415496  Train accuracy: 0.8359375  Test accuracy: 0.85546875\n",
      "Epoch: 70  Loss: 0.47201005  Train accuracy: 0.8203125  Test accuracy: 0.8203125\n",
      "Epoch: 80  Loss: 0.55239075  Train accuracy: 0.76171875  Test accuracy: 0.83203125\n",
      "Epoch: 90  Loss: 0.4115301  Train accuracy: 0.84375  Test accuracy: 0.796875\n",
      "Epoch: 100  Loss: 0.4304093  Train accuracy: 0.8515625  Test accuracy: 0.82421875\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_features], name='features')\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_labels], name='labels')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    train_op, loss, train_accuracy, test_accuracy = model(X, y, Layers, LR, drop_rate)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        for X_batch, y_batch in get_next_batch(X_train, y_train, Batch_size):\n",
    "            _, l, train_acc = sess.run([train_op, loss, train_accuracy], {X: X_batch, y: y_batch})\n",
    "            \n",
    "        if epoch%10 == 0:\n",
    "            for X_batch, y_batch in get_next_batch(X_test, y_test, Batch_size):\n",
    "                test_acc, = sess.run([test_accuracy], {X: X_batch, y: y_batch})\n",
    "            print(\"Epoch:\", epoch, \" Loss:\", l, \" Train accuracy:\", train_acc, \" Test accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

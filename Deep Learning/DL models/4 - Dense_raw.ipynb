{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('Datasets/Fashion_MNIST/X_train.npy')\n",
    "X_test = np.load('Datasets/Fashion_MNIST/X_test.npy')\n",
    "y_train = np.load('Datasets/Fashion_MNIST/y_train.npy')\n",
    "y_test = np.load('Datasets/Fashion_MNIST/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encoder.transform(y_train.reshape(-1, 1))\n",
    "y_test = encoder.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(X, y, size):\n",
    "    m = X.shape[0]\n",
    "    index = np.random.permutation(np.arange(m))\n",
    "    for i in range(m//size):\n",
    "        batch_i = index[i*size: i*size+size]\n",
    "        yield X[batch_i], y[batch_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 512\n",
    "LR = 0.0005\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "n_labels = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, n_features], name='features')\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_labels], name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layers = [256, 128, 64, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xavier = tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(xavier([n_features, Layers[0]]))\n",
    "b1 = tf.Variable(tf.zeros([Layers[0]]))\n",
    "\n",
    "W2 = tf.Variable(xavier([Layers[0], Layers[1]]))\n",
    "b2 = tf.Variable(tf.zeros([Layers[1]]))\n",
    "\n",
    "W3 = tf.Variable(xavier([Layers[1], Layers[2]]))\n",
    "b3 = tf.Variable(tf.zeros([Layers[2]]))\n",
    "\n",
    "W4 = tf.Variable(xavier([Layers[2], Layers[3]]))\n",
    "b4 = tf.Variable(tf.zeros([Layers[3]]))\n",
    "\n",
    "W5 = tf.Variable(xavier([Layers[3], n_labels]))\n",
    "b5 = tf.Variable(tf.zeros([n_labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = tf.add(tf.matmul(X, W1), b1)\n",
    "A1 = tf.tanh(Z1)\n",
    "\n",
    "Z2 = tf.add(tf.matmul(A1, W2), b2)\n",
    "A2 = tf.tanh(Z2)\n",
    "\n",
    "Z3 = tf.add(tf.matmul(A2, W3), b3)\n",
    "A3 = tf.tanh(Z3)\n",
    "\n",
    "Z4 = tf.add(tf.matmul(A3, W4), b4)\n",
    "A4 = tf.tanh(Z4)\n",
    "\n",
    "Z5 = tf.add(tf.matmul(A4, W5), b5)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(Z5,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=Z5)\n",
    "\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=LR).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10  Loss: 0.5545477  Train accuracy: 0.7988281  Test accuracy: 0.7842\n",
      "Epoch: 20  Loss: 0.5009248  Train accuracy: 0.80078125  Test accuracy: 0.8029\n",
      "Epoch: 30  Loss: 0.54362077  Train accuracy: 0.8105469  Test accuracy: 0.8089\n",
      "Epoch: 40  Loss: 0.44510463  Train accuracy: 0.8417969  Test accuracy: 0.8053\n",
      "Epoch: 50  Loss: 0.5420026  Train accuracy: 0.78515625  Test accuracy: 0.7977\n",
      "Epoch: 60  Loss: 0.49907446  Train accuracy: 0.8125  Test accuracy: 0.8135\n",
      "Epoch: 70  Loss: 0.4249103  Train accuracy: 0.8378906  Test accuracy: 0.8199\n",
      "Epoch: 80  Loss: 0.44562423  Train accuracy: 0.8261719  Test accuracy: 0.8245\n",
      "Epoch: 90  Loss: 0.435998  Train accuracy: 0.83984375  Test accuracy: 0.8305\n",
      "Epoch: 100  Loss: 0.4230092  Train accuracy: 0.84375  Test accuracy: 0.8258\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        for i, (X_batch, y_batch) in enumerate(get_next_batch(X_train, y_train, Batch_size)):\n",
    "            _, c, train_acc = sess.run([train_op, cost, accuracy], {X: X_batch, y: y_batch})\n",
    "            \n",
    "        if epoch%10 == 0:\n",
    "            test_acc, = sess.run([accuracy], {X: X_test, y: y_test})\n",
    "            print(\"Epoch:\", epoch, \" Loss:\", c, \" Train accuracy:\", train_acc, \" Test accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

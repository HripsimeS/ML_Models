{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('Solarize_Light2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepration of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = h5py.File('datasets/train_cat.h5', \"r\")\n",
    "test_dataset = h5py.File('datasets/test_cat.h5', \"r\")\n",
    "\n",
    "train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "# Reshaping the target labels to a row Vector instead of column Vector\n",
    "train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0])) \n",
    "test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "\n",
    "classes = np.array(['not-cat', 'cat']) # the list of classes\n",
    "\n",
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig[0].shape[0]\n",
    "\n",
    "#flattening\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1)\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1)\n",
    "\n",
    "#correct dim\n",
    "train_set_x_flatten = train_set_x_flatten.T\n",
    "test_set_x_flatten = test_set_x_flatten.T\n",
    "\n",
    "# normalizing\n",
    "# values were from 0 to 255\n",
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x shape -> (12288, 209)\n",
      "train_set_y_orig shape -> (1, 209)\n",
      "test_set_x shape -> (12288, 50)\n",
      "test_set_y_orig shape -> (1, 50)\n"
     ]
    }
   ],
   "source": [
    "print (\"train_set_x shape ->\", train_set_x.shape)\n",
    "print (\"train_set_y_orig shape ->\", train_set_y_orig.shape)\n",
    "print (\"test_set_x shape ->\", test_set_x.shape)\n",
    "print (\"test_set_y_orig shape ->\", test_set_y_orig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hidden Layer\n",
    "\n",
    "<img src=\"OneHiddenLayer.png\" style=\"width:650px;height:400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the neural network structure \n",
    "    - n_0: the size of the input layer (n_x)\n",
    "    - n_1: the size of the hidden layer\n",
    "    - n_2: the size of the output layer (n_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the dimensions of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1./(1. + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y, hidden_layer=4):\n",
    "    n_0 = X.shape[0]\n",
    "    n_1 = hidden_layer\n",
    "    n_2 = Y.shape[0]\n",
    "    return (n_0, n_1, n_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_0, n_1, n_2):\n",
    "    \n",
    "    W1 = np.random.randn(n_1, n_0) * 0.01\n",
    "    b1 = np.zeros((n_1, 1))\n",
    "    W2 = np.random.randn(n_2, n_1) * 0.01\n",
    "    b2 = np.zeros((n_2, 1))\n",
    "    \n",
    "    assert (W1.shape == (n_1, n_0))\n",
    "    assert (b1.shape == (n_1, 1))\n",
    "    assert (W2.shape == (n_2, n_1))\n",
    "    assert (b2.shape == (n_2, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "\n",
    "    W1 = parameters[\"W1\"]   #shape(n_1, n_0)\n",
    "    b1 = parameters[\"b1\"]   #shape(n_1, 1)\n",
    "    W2 = parameters[\"W2\"]   #shape(n_2, n_1)\n",
    "    b2 = parameters[\"b2\"]   #shape(n_2, 1)\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1    \n",
    "    A1 = np.tanh(Z1)         \n",
    "    Z2 = np.dot(W2, A1) + b2 \n",
    "    A2 = sigmoid(Z2)           \n",
    "\n",
    "    assert(A2.shape == (1, X.shape[1])) #Number of data should match\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters):\n",
    "    \n",
    "    m = Y.shape[1] # number of data\n",
    "\n",
    "    logprobs = np.multiply(Y, np.log(A2)) + np.multiply(1-Y, np.log(1 - A2))\n",
    "    cost = -np.sum(logprobs)/m\n",
    "    \n",
    "    cost = np.squeeze(cost)     \n",
    "                                \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "\n",
    "    m = X.shape[1]\n",
    "\n",
    "    W1 = parameters[\"W1\"]   \n",
    "    W2 = parameters[\"W2\"]    \n",
    "    \n",
    "    A1 = cache[\"A1\"]         \n",
    "    A2 = cache[\"A2\"]        \n",
    "\n",
    "   \n",
    "    dZ2 = A2 - Y             #shape(1, m)\n",
    "    dW2 = np.dot(dZ2, A1.T)/m  #shape(n_2, n_1)\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True)/m #shape(n_2, 1)\n",
    "    dZ1 = np.dot(W2.T, dZ2) * ( 1-np.power(np.tanh(cache[\"Z1\"]), 2) ) #shape(n_1, m)\n",
    "    dW1 = np.dot(dZ1, X.T)/m #shape(n_1, n_0)\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True)/m #shape(n_1, 1)\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "\n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X, Y, n_1, num_iterations=10000, learning_rate=0.1, print_cost=False, print_test=False, X_test=None, y_test=None):\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    n_0 = layer_sizes(X, Y)[0]\n",
    "    n_2 = layer_sizes(X, Y)[2]\n",
    "    \n",
    "    parameters = initialize_parameters(n_0, n_1, n_2)\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    for i in range(1, num_iterations+1):\n",
    "         \n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        \n",
    "        cost = compute_cost(A2, Y, parameters)\n",
    " \n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    " \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        # Print the cost every 1000 iterations\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (f\"Cost after iteration {i}: {cost}\", end=\"  |  \")\n",
    "            if print_test:\n",
    "                test_predictions = predict(parameters, X_test)                \n",
    "                test_acc = 100 - np.mean(np.abs(test_predictions - y_test)) * 100\n",
    "                print(f\"test accuracy: {test_acc}\")                \n",
    "\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = np.array([ [0 if num<=0.5 else 1 for num in A2[0, :]] ]) #Turning probabilities to classes\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 500: 0.4885436388436988  |  test accuracy: 56.0\n",
      "Cost after iteration 1000: 0.27278126505608613  |  test accuracy: 60.0\n",
      "Cost after iteration 1500: 0.09879382681604416  |  test accuracy: 70.0\n",
      "Cost after iteration 2000: 0.054082137251847365  |  test accuracy: 70.0\n",
      "Cost after iteration 2500: 0.03551886899902286  |  test accuracy: 68.0\n",
      "Cost after iteration 3000: 0.025402582197411767  |  test accuracy: 66.0\n",
      "Cost after iteration 3500: 0.019334763424478  |  test accuracy: 66.0\n",
      "Cost after iteration 4000: 0.015211479043025921  |  test accuracy: 68.0\n",
      "Cost after iteration 4500: 0.012575217108374597  |  test accuracy: 68.0\n",
      "Cost after iteration 5000: 0.01073960318548639  |  test accuracy: 68.0\n",
      "Cost after iteration 5500: 0.009363938427583126  |  test accuracy: 68.0\n",
      "Cost after iteration 6000: 0.00829341398195627  |  test accuracy: 68.0\n",
      "Cost after iteration 6500: 0.007437269064112263  |  test accuracy: 68.0\n",
      "Cost after iteration 7000: 0.0067376116733104995  |  test accuracy: 68.0\n",
      "Cost after iteration 7500: 0.006155614666594241  |  test accuracy: 68.0\n",
      "Cost after iteration 8000: 0.005664247250710133  |  test accuracy: 68.0\n",
      "Cost after iteration 8500: 0.00524411783566544  |  test accuracy: 68.0\n",
      "Cost after iteration 9000: 0.004880962113509547  |  test accuracy: 68.0\n",
      "Cost after iteration 9500: 0.004564060285923801  |  test accuracy: 68.0\n",
      "Cost after iteration 10000: 0.004285205188578373  |  test accuracy: 68.0\n"
     ]
    }
   ],
   "source": [
    "parameters = nn_model(train_set_x,\n",
    "                      train_set_y_orig,\n",
    "                      n_1=8,\n",
    "                      num_iterations=10000,\n",
    "                      learning_rate=0.01,\n",
    "                      print_cost=True,\n",
    "                      print_test=True,\n",
    "                      X_test=test_set_x,\n",
    "                      y_test=test_set_y_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = predict(parameters, train_set_x)\n",
    "test_predictions = predict(parameters, test_set_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 100.0\n",
      "test accuracy: 68.0\n"
     ]
    }
   ],
   "source": [
    "train_acc = 100 - np.mean(np.abs(train_predictions - train_set_y_orig)) * 100\n",
    "test_acc = 100 - np.mean(np.abs(test_predictions - test_set_y_orig)) * 100\n",
    "print(f\"train accuracy: {train_acc}\")\n",
    "print(f\"test accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DNN.png\" style=\"width:800px;height:500px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** X -> *[Linear -> ReLU] (L-1 times)* -> Linear -> Sigmoid -> Yhat **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # Copying the list to not assign to the original\n",
    "    \n",
    "    dZ[Z <= 0] = 0 # Derivative, DZ is 0 where Z is negative\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_dnn(layer_dims):\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims) # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    Z = W.dot(A) + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1])) # check the dims\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "   \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model_forward(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    \n",
    "    cost = np.squeeze(cost) # make sure cost is just a number\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # Make AL and Y the same shape\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation=\"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, activation=\"relu\")\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2 \n",
    "\n",
    "    for l in range(1, L+1):\n",
    "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*grads[\"dW\" + str(l)]\n",
    "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate*grads[\"db\" + str(l)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "  \n",
    "    m = X.shape[1]\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    probas, caches = dnn_model_forward(X, parameters)\n",
    "\n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(X, Y, layers_dims, learning_rate = 0.001, num_iterations = 3000, print_cost=False):\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    \n",
    "    parameters = initialize_parameters_dnn(layers_dims)\n",
    "    \n",
    "    for i in range(1, num_iterations+1):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = dnn_model_forward(X, parameters)\n",
    "        \n",
    "        # Compute cost.\n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        # Backward propagation.\n",
    "        grads = dnn_model_backward(AL, Y, caches)\n",
    " \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                \n",
    "        if i % 100 == 0:\n",
    "            if cost != [] and cost == costs[-1]:\n",
    "                break\n",
    "            costs.append(cost)\n",
    "            # Print the cost every 100 training example\n",
    "            if print_cost:\n",
    "                print (f\"Cost after iteration {i}: {cost}\")\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            learning_rate = max(0.00001, learning_rate*.9)\n",
    "\n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "train_dataset = h5py.File('datasets/train_cat.h5', \"r\")\n",
    "test_dataset = h5py.File('datasets/test_cat.h5', \"r\")\n",
    "\n",
    "train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "# Reshaping the target labels to a row Vector instead of column Vector\n",
    "train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0])) \n",
    "test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "\n",
    "classes = np.array(['not-cat', 'cat']) # the list of classes\n",
    "\n",
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig[0].shape[0]\n",
    "\n",
    "#flattening\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1)\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1)\n",
    "\n",
    "#correct dim\n",
    "train_set_x_flatten = train_set_x_flatten.T\n",
    "test_set_x_flatten = test_set_x_flatten.T\n",
    "\n",
    "# normalizing\n",
    "# values were from 0 to 255\n",
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x shape -> (12288, 209)\n",
      "train_set_y_orig shape -> (1, 209)\n",
      "test_set_x shape -> (12288, 50)\n",
      "test_set_y_orig shape -> (1, 50)\n"
     ]
    }
   ],
   "source": [
    "print (\"train_set_x shape ->\", train_set_x.shape)\n",
    "print (\"train_set_y_orig shape ->\", train_set_y_orig.shape)\n",
    "print (\"test_set_x shape ->\", test_set_x.shape)\n",
    "print (\"test_set_y_orig shape ->\", test_set_y_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 100: 0.6408847211634631\n",
      "Cost after iteration 200: 0.6051086742888109\n",
      "Cost after iteration 300: 0.5372169320055384\n",
      "Cost after iteration 400: 0.4560830383165973\n",
      "Cost after iteration 500: 0.4343077275505305\n",
      "Cost after iteration 600: 0.39201072328050396\n",
      "Cost after iteration 700: 0.3478189823031774\n",
      "Cost after iteration 800: 0.29618850570553235\n",
      "Cost after iteration 900: 0.27782304506739613\n",
      "Cost after iteration 1000: 0.16085157188896052\n",
      "Cost after iteration 1100: 0.12416958357355942\n",
      "Cost after iteration 1200: 0.1029317993012278\n",
      "Cost after iteration 1300: 0.08055348297939466\n",
      "Cost after iteration 1400: 0.06811042412572198\n",
      "Cost after iteration 1500: 0.05680514327621626\n",
      "Cost after iteration 1600: 0.046853102393372995\n",
      "Cost after iteration 1700: 0.04021407814607501\n",
      "Cost after iteration 1800: 0.03512772141956908\n",
      "Cost after iteration 1900: 0.03098579397129617\n",
      "Cost after iteration 2000: 0.027520288417277435\n",
      "Cost after iteration 2100: 0.02490403958816167\n",
      "Cost after iteration 2200: 0.022682745138104567\n",
      "Cost after iteration 2300: 0.020766538249333163\n",
      "Cost after iteration 2400: 0.019079444897121788\n",
      "Cost after iteration 2500: 0.01762610954271267\n",
      "Cost after iteration 2600: 0.016345340066681494\n",
      "Cost after iteration 2700: 0.015205715945046779\n",
      "Cost after iteration 2800: 0.014192435721236804\n",
      "Cost after iteration 2900: 0.013291469566780874\n",
      "Cost after iteration 3000: 0.012482648911473077\n",
      "Cost after iteration 3100: 0.011820337024564564\n",
      "Cost after iteration 3200: 0.011218856073439637\n",
      "Cost after iteration 3300: 0.010666199301125577\n",
      "Cost after iteration 3400: 0.010164654612731716\n",
      "Cost after iteration 3500: 0.009694487386282931\n",
      "Cost after iteration 3600: 0.009263955372825594\n",
      "Cost after iteration 3700: 0.00886427399618023\n",
      "Cost after iteration 3800: 0.00849462985710198\n",
      "Cost after iteration 3900: 0.008151042210913454\n",
      "Cost after iteration 4000: 0.007831445021851537\n",
      "Cost after iteration 4100: 0.007560260035006445\n",
      "Cost after iteration 4200: 0.007304686665007339\n",
      "Cost after iteration 4300: 0.007066724467297522\n",
      "Cost after iteration 4400: 0.006840537621753614\n",
      "Cost after iteration 4500: 0.006625879280141889\n",
      "Cost after iteration 4600: 0.006423457364441812\n",
      "Cost after iteration 4700: 0.0062312650866411376\n",
      "Cost after iteration 4800: 0.0060507945484281\n",
      "Cost after iteration 4900: 0.005876716291684815\n",
      "Cost after iteration 5000: 0.005712424384521078\n",
      "Cost after iteration 5100: 0.005571808166365157\n",
      "Cost after iteration 5200: 0.005437443650345143\n",
      "Cost after iteration 5300: 0.005307370545795099\n",
      "Cost after iteration 5400: 0.005183279792615904\n",
      "Cost after iteration 5500: 0.005065091260477443\n",
      "Cost after iteration 5600: 0.004950983298646115\n",
      "Cost after iteration 5700: 0.004840803135533031\n",
      "Cost after iteration 5800: 0.00473513895940233\n",
      "Cost after iteration 5900: 0.004634673105802104\n",
      "Cost after iteration 6000: 0.004536247901802622\n",
      "Cost after iteration 6100: 0.0044520633835101135\n",
      "Cost after iteration 6200: 0.004369329531594504\n",
      "Cost after iteration 6300: 0.004290059620235638\n",
      "Cost after iteration 6400: 0.004213398181174345\n",
      "Cost after iteration 6500: 0.004138994793704776\n",
      "Cost after iteration 6600: 0.004066929788971054\n",
      "Cost after iteration 6700: 0.003997145024967832\n",
      "Cost after iteration 6800: 0.003929411638748064\n",
      "Cost after iteration 6900: 0.0038635569115939706\n",
      "Cost after iteration 7000: 0.003800049616224902\n",
      "Cost after iteration 7100: 0.003744314136960296\n",
      "Cost after iteration 7200: 0.0036896728285865706\n",
      "Cost after iteration 7300: 0.003636723914467599\n",
      "Cost after iteration 7400: 0.0035853895720880935\n",
      "Cost after iteration 7500: 0.003534941205372663\n",
      "Cost after iteration 7600: 0.003485869899767771\n",
      "Cost after iteration 7700: 0.003438150973036989\n",
      "Cost after iteration 7800: 0.003391266107746261\n",
      "Cost after iteration 7900: 0.0033456952423641328\n",
      "Cost after iteration 8000: 0.003301440450145239\n",
      "Cost after iteration 8100: 0.0032622199256658333\n",
      "Cost after iteration 8200: 0.0032239517572643706\n",
      "Cost after iteration 8300: 0.0031864335757997024\n",
      "Cost after iteration 8400: 0.003149734854884199\n",
      "Cost after iteration 8500: 0.003113820479736454\n",
      "Cost after iteration 8600: 0.003078597634274092\n",
      "Cost after iteration 8700: 0.0030440314900697556\n",
      "Cost after iteration 8800: 0.0030101476633841366\n",
      "Cost after iteration 8900: 0.0029770540931734015\n",
      "Cost after iteration 9000: 0.0029445995351992577\n",
      "Cost after iteration 9100: 0.002915727287863143\n",
      "Cost after iteration 9200: 0.0028876391953334144\n",
      "Cost after iteration 9300: 0.0028598686558852096\n",
      "Cost after iteration 9400: 0.002832627692029585\n",
      "Cost after iteration 9500: 0.0028057969750959247\n",
      "Cost after iteration 9600: 0.0027795632760887123\n",
      "Cost after iteration 9700: 0.002753679174972864\n",
      "Cost after iteration 9800: 0.002728244001236035\n",
      "Cost after iteration 9900: 0.0027031405157991266\n",
      "Cost after iteration 10000: 0.0026785054124814464\n",
      "Cost after iteration 10100: 0.00265670352074524\n",
      "Cost after iteration 10200: 0.0026352389517820796\n",
      "Cost after iteration 10300: 0.0026140269335585054\n",
      "Cost after iteration 10400: 0.002593216665548339\n",
      "Cost after iteration 10500: 0.002572635677133331\n",
      "Cost after iteration 10600: 0.0025522923979651143\n",
      "Cost after iteration 10700: 0.00253243569226386\n",
      "Cost after iteration 10800: 0.0025125545943979273\n",
      "Cost after iteration 10900: 0.0024931196163511917\n",
      "Cost after iteration 11000: 0.0024739782012594023\n",
      "Cost after iteration 11100: 0.0024568983192901892\n",
      "Cost after iteration 11200: 0.0024401818681804737\n",
      "Cost after iteration 11300: 0.002423513259394034\n",
      "Cost after iteration 11400: 0.002407204474875051\n",
      "Cost after iteration 11500: 0.0023909462805755746\n",
      "Cost after iteration 11600: 0.0023749741749108343\n",
      "Cost after iteration 11700: 0.002359093999466736\n",
      "Cost after iteration 11800: 0.002343605590655459\n",
      "Cost after iteration 11900: 0.0023281257099418\n",
      "Cost after iteration 12000: 0.0023128291345808102\n",
      "Cost after iteration 12100: 0.002299274428645537\n",
      "Cost after iteration 12200: 0.0022858203535644113\n",
      "Cost after iteration 12300: 0.0022725349542599034\n",
      "Cost after iteration 12400: 0.0022593736179836042\n",
      "Cost after iteration 12500: 0.0022463706538532924\n",
      "Cost after iteration 12600: 0.0022335116002874093\n",
      "Cost after iteration 12700: 0.002220762415277008\n",
      "Cost after iteration 12800: 0.002208143584385327\n",
      "Cost after iteration 12900: 0.0021956745730524947\n",
      "Cost after iteration 13000: 0.002183338895688783\n",
      "Cost after iteration 13100: 0.0021723093270003546\n",
      "Cost after iteration 13200: 0.0021614171424336054\n",
      "Cost after iteration 13300: 0.002150584761735622\n",
      "Cost after iteration 13400: 0.002139885492336105\n",
      "Cost after iteration 13500: 0.0021293207581731454\n",
      "Cost after iteration 13600: 0.002118755940364376\n",
      "Cost after iteration 13700: 0.0021083476300427667\n",
      "Cost after iteration 13800: 0.0020980043701286904\n",
      "Cost after iteration 13900: 0.0020877899890469277\n",
      "Cost after iteration 14000: 0.002077595778553327\n",
      "Cost after iteration 14100: 0.0020685542685282493\n",
      "Cost after iteration 14200: 0.002059545854191288\n",
      "Cost after iteration 14300: 0.002050639441961538\n",
      "Cost after iteration 14400: 0.0020418574304326403\n",
      "Cost after iteration 14500: 0.0020330342411072227\n",
      "Cost after iteration 14600: 0.002024311313853694\n",
      "Cost after iteration 14700: 0.002015658516149465\n",
      "Cost after iteration 14800: 0.0020071131432472136\n",
      "Cost after iteration 14900: 0.001998600678084793\n",
      "Cost after iteration 15000: 0.001990204625301319\n",
      "Cost after iteration 15100: 0.0019826154696061596\n",
      "Cost after iteration 15200: 0.0019750780451066813\n",
      "Cost after iteration 15300: 0.0019677030251824034\n",
      "Cost after iteration 15400: 0.0019602566359314066\n",
      "Cost after iteration 15500: 0.0019529212105291076\n",
      "Cost after iteration 15600: 0.0019456412499441141\n",
      "Cost after iteration 15700: 0.0019384439077657128\n",
      "Cost after iteration 15800: 0.0019312582217372505\n",
      "Cost after iteration 15900: 0.0019240699489569215\n",
      "Cost after iteration 16000: 0.0019170099544350955\n",
      "Cost after iteration 16100: 0.0019106196230333592\n",
      "Cost after iteration 16200: 0.0019043149734613422\n",
      "Cost after iteration 16300: 0.0018980404691774832\n",
      "Cost after iteration 16400: 0.0018918190663586721\n",
      "Cost after iteration 16500: 0.0018856040180254613\n",
      "Cost after iteration 16600: 0.001879447599164903\n",
      "Cost after iteration 16700: 0.001873334870887288\n",
      "Cost after iteration 16800: 0.0018672407503577512\n",
      "Cost after iteration 16900: 0.0018612061441808736\n",
      "Cost after iteration 17000: 0.0018551639964726624\n",
      "Cost after iteration 17100: 0.0018498086723416404\n",
      "Cost after iteration 17200: 0.001844463632829406\n",
      "Cost after iteration 17300: 0.0018391125788704678\n",
      "Cost after iteration 17400: 0.0018338149475037792\n",
      "Cost after iteration 17500: 0.0018285908806980563\n",
      "Cost after iteration 17600: 0.0018233088943260382\n",
      "Cost after iteration 17700: 0.0018180971171130912\n",
      "Cost after iteration 17800: 0.001812906520423301\n",
      "Cost after iteration 17900: 0.0018077639497530186\n",
      "Cost after iteration 18000: 0.0018026185555271065\n",
      "Cost after iteration 18100: 0.0017980103544535414\n",
      "Cost after iteration 18200: 0.0017934242250977049\n",
      "Cost after iteration 18300: 0.0017889033153159933\n",
      "Cost after iteration 18400: 0.0017843314321830564\n",
      "Cost after iteration 18500: 0.0017798288383229267\n",
      "Cost after iteration 18600: 0.0017753422596392277\n",
      "Cost after iteration 18700: 0.001770854894688518\n",
      "Cost after iteration 18800: 0.0017664047906089191\n",
      "Cost after iteration 18900: 0.0017619735588116575\n",
      "Cost after iteration 19000: 0.0017575707738565953\n",
      "Cost after iteration 19100: 0.0017536248721386437\n",
      "Cost after iteration 19200: 0.0017496835260196997\n",
      "Cost after iteration 19300: 0.001745746501752408\n",
      "Cost after iteration 19400: 0.0017418424048653476\n",
      "Cost after iteration 19500: 0.0017379848088541802\n",
      "Cost after iteration 19600: 0.0017340788718084655\n",
      "Cost after iteration 19700: 0.0017302333808543976\n",
      "Cost after iteration 19800: 0.0017263858101857314\n",
      "Cost after iteration 19900: 0.0017225590280102582\n",
      "Cost after iteration 20000: 0.0017187550187420977\n",
      "Cost after iteration 20100: 0.0017153139686830034\n",
      "Cost after iteration 20200: 0.0017119083688294965\n",
      "Cost after iteration 20300: 0.0017085407214300547\n",
      "Cost after iteration 20400: 0.001705148244213011\n",
      "Cost after iteration 20500: 0.001701783295903405\n",
      "Cost after iteration 20600: 0.0016984401116886501\n",
      "Cost after iteration 20700: 0.0016950779967169825\n",
      "Cost after iteration 20800: 0.0016917585668413788\n",
      "Cost after iteration 20900: 0.0016884231336401754\n",
      "Cost after iteration 21000: 0.0016851241279368355\n",
      "Cost after iteration 21100: 0.0016821380020512608\n",
      "Cost after iteration 21200: 0.0016791881290849388\n",
      "Cost after iteration 21300: 0.00167623989240092\n",
      "Cost after iteration 21400: 0.0016733208009322906\n",
      "Cost after iteration 21500: 0.0016703696457391005\n",
      "Cost after iteration 21600: 0.0016674817969488847\n",
      "Cost after iteration 21700: 0.0016645424492887737\n",
      "Cost after iteration 21800: 0.0016616469615028551\n",
      "Cost after iteration 21900: 0.0016587697673435336\n",
      "Cost after iteration 22000: 0.0016558730761263125\n",
      "Cost after iteration 22100: 0.0016532836533085312\n",
      "Cost after iteration 22200: 0.001650707202371655\n",
      "Cost after iteration 22300: 0.0016481186223977116\n",
      "Cost after iteration 22400: 0.0016455812456326376\n",
      "Cost after iteration 22500: 0.0016430118117880972\n",
      "Cost after iteration 22600: 0.0016404478629186367\n",
      "Cost after iteration 22700: 0.0016379166610166291\n",
      "Cost after iteration 22800: 0.0016353718155855323\n",
      "Cost after iteration 22900: 0.0016328408037019442\n",
      "Cost after iteration 23000: 0.0016303185699051638\n",
      "Cost after iteration 23100: 0.001628069052639598\n",
      "Cost after iteration 23200: 0.001625799968034056\n",
      "Cost after iteration 23300: 0.0016235443559728326\n",
      "Cost after iteration 23400: 0.0016212959712304585\n",
      "Cost after iteration 23500: 0.0016190741474810587\n",
      "Cost after iteration 23600: 0.0016168387560527024\n",
      "Cost after iteration 23700: 0.0016146092220281473\n",
      "Cost after iteration 23800: 0.0016123664423132568\n",
      "Cost after iteration 23900: 0.001610150799312483\n",
      "Cost after iteration 24000: 0.0016079465141901114\n",
      "Cost after iteration 24100: 0.001605967736749406\n",
      "Cost after iteration 24200: 0.0016039702856851066\n",
      "Cost after iteration 24300: 0.0016019925544315397\n",
      "Cost after iteration 24400: 0.0016000244842598356\n",
      "Cost after iteration 24500: 0.001598056819803918\n",
      "Cost after iteration 24600: 0.0015961016404994809\n",
      "Cost after iteration 24700: 0.001594127418471035\n",
      "Cost after iteration 24800: 0.0015921695959441066\n",
      "Cost after iteration 24900: 0.0015902223625225173\n",
      "Cost after iteration 25000: 0.0015882918580937485\n",
      "Cost after iteration 25100: 0.0015865220814848468\n",
      "Cost after iteration 25200: 0.0015847802621905857\n",
      "Cost after iteration 25300: 0.0015830375236571643\n",
      "Cost after iteration 25400: 0.001581303510514582\n",
      "Cost after iteration 25500: 0.0015795607076104076\n",
      "Cost after iteration 25600: 0.0015778299943233862\n",
      "Cost after iteration 25700: 0.0015761084291900339\n",
      "Cost after iteration 25800: 0.0015743872855268496\n",
      "Cost after iteration 25900: 0.0015726705264105553\n",
      "Cost after iteration 26000: 0.0015709514953231552\n",
      "Cost after iteration 26100: 0.0015693977186276627\n",
      "Cost after iteration 26200: 0.0015678634326015447\n",
      "Cost after iteration 26300: 0.0015663306896764714\n",
      "Cost after iteration 26400: 0.0015647979199318832\n",
      "Cost after iteration 26500: 0.0015632592807454332\n",
      "Cost after iteration 26600: 0.001561729466804925\n",
      "Cost after iteration 26700: 0.0015602074310003863\n",
      "Cost after iteration 26800: 0.0015586811712304078\n",
      "Cost after iteration 26900: 0.0015571613046201176\n",
      "Cost after iteration 27000: 0.0015556418385110245\n",
      "Cost after iteration 27100: 0.0015542754888073283\n",
      "Cost after iteration 27200: 0.0015529163687749241\n",
      "Cost after iteration 27300: 0.001551552751793957\n",
      "Cost after iteration 27400: 0.0015501967613278439\n",
      "Cost after iteration 27500: 0.0015488462965768304\n",
      "Cost after iteration 27600: 0.001547494633192823\n",
      "Cost after iteration 27700: 0.0015461444898883974\n",
      "Cost after iteration 27800: 0.0015447888487431947\n",
      "Cost after iteration 27900: 0.001543442178716467\n",
      "Cost after iteration 28000: 0.001542098816822026\n",
      "Cost after iteration 28100: 0.0015408901497917238\n",
      "Cost after iteration 28200: 0.0015396893279494693\n",
      "Cost after iteration 28300: 0.0015384803256326567\n",
      "Cost after iteration 28400: 0.001537276451274622\n",
      "Cost after iteration 28500: 0.0015360858452921427\n",
      "Cost after iteration 28600: 0.0015348759003612766\n",
      "Cost after iteration 28700: 0.0015336813290859968\n",
      "Cost after iteration 28800: 0.0015324843557885477\n",
      "Cost after iteration 28900: 0.0015312896002139568\n",
      "Cost after iteration 29000: 0.0015300969973335889\n",
      "Cost after iteration 29100: 0.0015290305328288\n",
      "Cost after iteration 29200: 0.001527958043014612\n",
      "Cost after iteration 29300: 0.0015268815963713639\n",
      "Cost after iteration 29400: 0.0015258164564556857\n",
      "Cost after iteration 29500: 0.0015247451565162092\n",
      "Cost after iteration 29600: 0.0015236841480120032\n",
      "Cost after iteration 29700: 0.0015226182652844503\n",
      "Cost after iteration 29800: 0.0015215593662842007\n",
      "Cost after iteration 29900: 0.0015204974125587625\n",
      "Cost after iteration 30000: 0.0015194409890773046\n",
      "Cost after iteration 30100: 0.0015184890980540627\n",
      "Cost after iteration 30200: 0.0015175310138585468\n",
      "Cost after iteration 30300: 0.0015165817880295686\n",
      "Cost after iteration 30400: 0.0015156312144507683\n",
      "Cost after iteration 30500: 0.0015146859509701696\n",
      "Cost after iteration 30600: 0.001513738145460057\n",
      "Cost after iteration 30700: 0.0015127908929548027\n",
      "Cost after iteration 30800: 0.0015118497149154326\n",
      "Cost after iteration 30900: 0.0015108992041723303\n",
      "Cost after iteration 31000: 0.0015099600270963166\n",
      "Cost after iteration 31100: 0.0015091129474991787\n",
      "Cost after iteration 31200: 0.0015082695766887862\n",
      "Cost after iteration 31300: 0.0015074179154561608\n",
      "Cost after iteration 31400: 0.0015065711114578186\n",
      "Cost after iteration 31500: 0.0015057265915282263\n",
      "Cost after iteration 31600: 0.0015048875666311072\n",
      "Cost after iteration 31700: 0.001504041827677236\n",
      "Cost after iteration 31800: 0.0015032039805461213\n",
      "Cost after iteration 31900: 0.0015023624736446735\n",
      "Cost after iteration 32000: 0.0015015251907492173\n",
      "Cost after iteration 32100: 0.0015007692342577563\n",
      "Cost after iteration 32200: 0.0015000106954560716\n",
      "Cost after iteration 32300: 0.001499257149425149\n",
      "Cost after iteration 32400: 0.0014985080138431538\n",
      "Cost after iteration 32500: 0.001497752270661964\n",
      "Cost after iteration 32600: 0.0014969986233826552\n",
      "Cost after iteration 32700: 0.0014962480288800849\n",
      "Cost after iteration 32800: 0.0014955067057990732\n",
      "Cost after iteration 32900: 0.0014947493659948255\n",
      "Cost after iteration 33000: 0.0014940015820439371\n",
      "Cost after iteration 33100: 0.0014933259920007355\n",
      "Cost after iteration 33200: 0.0014926530686034814\n",
      "Cost after iteration 33300: 0.0014919811083554265\n",
      "Cost after iteration 33400: 0.0014913136788870587\n",
      "Cost after iteration 33500: 0.0014906382711158523\n",
      "Cost after iteration 33600: 0.0014899675511970865\n",
      "Cost after iteration 33700: 0.0014892959832732769\n",
      "Cost after iteration 33800: 0.001488628486534803\n",
      "Cost after iteration 33900: 0.001487962679360782\n",
      "Cost after iteration 34000: 0.0014872887329791613\n",
      "Cost after iteration 34100: 0.0014866919427097374\n",
      "Cost after iteration 34200: 0.0014860898492862508\n",
      "Cost after iteration 34300: 0.0014854884083899881\n",
      "Cost after iteration 34400: 0.0014848924267982873\n",
      "Cost after iteration 34500: 0.0014842898407410924\n",
      "Cost after iteration 34600: 0.0014836906841403969\n",
      "Cost after iteration 34700: 0.001483089844395289\n",
      "Cost after iteration 34800: 0.0014824920704784093\n",
      "Cost after iteration 34900: 0.001481896375486156\n",
      "Cost after iteration 35000: 0.0014812987390297255\n",
      "Cost after iteration 35100: 0.0014807623338826841\n",
      "Cost after iteration 35200: 0.0014802252926647893\n",
      "Cost after iteration 35300: 0.001479686865173802\n",
      "Cost after iteration 35400: 0.00147915320361663\n",
      "Cost after iteration 35500: 0.0014786168841567175\n",
      "Cost after iteration 35600: 0.0014780820237729234\n",
      "Cost after iteration 35700: 0.0014775481698874576\n",
      "Cost after iteration 35800: 0.0014770109390686468\n",
      "Cost after iteration 35900: 0.0014764790712422718\n",
      "Cost after iteration 36000: 0.0014759437875938044\n",
      "Cost after iteration 36100: 0.0014754630971483326\n",
      "Cost after iteration 36200: 0.0014749823759110368\n",
      "Cost after iteration 36300: 0.0014745017320206472\n",
      "Cost after iteration 36400: 0.0014740224940376224\n",
      "Cost after iteration 36500: 0.001473547547456418\n",
      "Cost after iteration 36600: 0.00147306733835503\n",
      "Cost after iteration 36700: 0.0014725907645586323\n",
      "Cost after iteration 36800: 0.0014721087312272463\n",
      "Cost after iteration 36900: 0.0014716333411294467\n",
      "Cost after iteration 37000: 0.0014711537692144072\n",
      "Cost after iteration 37100: 0.0014707256678957914\n",
      "Cost after iteration 37200: 0.0014702933875368135\n",
      "Cost after iteration 37300: 0.0014698662883100714\n",
      "Cost after iteration 37400: 0.0014694356519679714\n",
      "Cost after iteration 37500: 0.0014690072640504515\n",
      "Cost after iteration 37600: 0.001468578784117257\n",
      "Cost after iteration 37700: 0.001468150900932975\n",
      "Cost after iteration 37800: 0.0014677221375180563\n",
      "Cost after iteration 37900: 0.0014672976817758836\n",
      "Cost after iteration 38000: 0.0014668676585409372\n",
      "Cost after iteration 38100: 0.0014664827727044914\n",
      "Cost after iteration 38200: 0.0014660975557140227\n",
      "Cost after iteration 38300: 0.001465713725128353\n",
      "Cost after iteration 38400: 0.0014653305964978552\n",
      "Cost after iteration 38500: 0.0014649483030427088\n",
      "Cost after iteration 38600: 0.0014645650682042779\n",
      "Cost after iteration 38700: 0.0014641797812494973\n",
      "Cost after iteration 38800: 0.0014637947813828068\n",
      "Cost after iteration 38900: 0.001463411515370754\n",
      "Cost after iteration 39000: 0.0014630306679307913\n",
      "Cost after iteration 39100: 0.0014626863426397507\n",
      "Cost after iteration 39200: 0.0014623393782640906\n",
      "Cost after iteration 39300: 0.001461995536599617\n",
      "Cost after iteration 39400: 0.001461653568040864\n",
      "Cost after iteration 39500: 0.001461308204382499\n",
      "Cost after iteration 39600: 0.0014609660749127357\n",
      "Cost after iteration 39700: 0.001460621665635379\n",
      "Cost after iteration 39800: 0.0014602796193227791\n",
      "Cost after iteration 39900: 0.0014599370729512936\n",
      "Cost after iteration 40000: 0.0014595913710175401\n",
      "Cost after iteration 40100: 0.0014592840075947672\n",
      "Cost after iteration 40200: 0.001458973884986262\n",
      "Cost after iteration 40300: 0.0014586647104992431\n",
      "Cost after iteration 40400: 0.0014583563774357511\n",
      "Cost after iteration 40500: 0.0014580471994586305\n",
      "Cost after iteration 40600: 0.0014577396221179988\n",
      "Cost after iteration 40700: 0.0014574320938386186\n",
      "Cost after iteration 40800: 0.0014571246145818502\n",
      "Cost after iteration 40900: 0.0014568170022596317\n",
      "Cost after iteration 41000: 0.0014565097510543137\n",
      "Cost after iteration 41100: 0.0014562310942657565\n",
      "Cost after iteration 41200: 0.0014559543578342472\n",
      "Cost after iteration 41300: 0.0014556801716386443\n",
      "Cost after iteration 41400: 0.0014554018784979383\n",
      "Cost after iteration 41500: 0.001455124707511092\n",
      "Cost after iteration 41600: 0.0014548483604415686\n",
      "Cost after iteration 41700: 0.0014545724379235292\n",
      "Cost after iteration 41800: 0.0014542961711921294\n",
      "Cost after iteration 41900: 0.001454020753815609\n",
      "Cost after iteration 42000: 0.0014537447106704497\n",
      "Cost after iteration 42100: 0.0014534956153966583\n",
      "Cost after iteration 42200: 0.0014532472967040393\n",
      "Cost after iteration 42300: 0.0014529997188709\n",
      "Cost after iteration 42400: 0.0014527537784204138\n",
      "Cost after iteration 42500: 0.0014525035675825508\n",
      "Cost after iteration 42600: 0.0014522575333453063\n",
      "Cost after iteration 42700: 0.0014520085803811957\n",
      "Cost after iteration 42800: 0.0014517606711243148\n",
      "Cost after iteration 42900: 0.0014515146569499466\n",
      "Cost after iteration 43000: 0.0014512659838561534\n",
      "Cost after iteration 43100: 0.0014510417902821532\n",
      "Cost after iteration 43200: 0.0014508200584490382\n",
      "Cost after iteration 43300: 0.0014505963974114848\n",
      "Cost after iteration 43400: 0.001450375432712251\n",
      "Cost after iteration 43500: 0.0014501523151100445\n",
      "Cost after iteration 43600: 0.0014499300746166567\n",
      "Cost after iteration 43700: 0.0014497086383376614\n",
      "Cost after iteration 43800: 0.0014494854570908924\n",
      "Cost after iteration 43900: 0.0014492648820530953\n",
      "Cost after iteration 44000: 0.0014490407278509047\n",
      "Cost after iteration 44100: 0.0014488409574002009\n",
      "Cost after iteration 44200: 0.0014486402360298176\n",
      "Cost after iteration 44300: 0.0014484408387955704\n",
      "Cost after iteration 44400: 0.0014482409993513625\n",
      "Cost after iteration 44500: 0.0014480420405461884\n",
      "Cost after iteration 44600: 0.0014478419517313797\n",
      "Cost after iteration 44700: 0.0014476418853168257\n",
      "Cost after iteration 44800: 0.001447442360744024\n",
      "Cost after iteration 44900: 0.0014472441024493221\n",
      "Cost after iteration 45000: 0.0014470455967611792\n",
      "Cost after iteration 45100: 0.0014468634064078605\n",
      "Cost after iteration 45200: 0.0014466841452641418\n",
      "Cost after iteration 45300: 0.0014465048009328105\n",
      "Cost after iteration 45400: 0.0014463256959461697\n",
      "Cost after iteration 45500: 0.0014461473492335042\n",
      "Cost after iteration 45600: 0.0014459670576264093\n",
      "Cost after iteration 45700: 0.0014457885918259098\n",
      "Cost after iteration 45800: 0.0014456088471161116\n",
      "Cost after iteration 45900: 0.0014454294836196628\n",
      "Cost after iteration 46000: 0.0014452506842561053\n",
      "Cost after iteration 46100: 0.0014450903138210295\n",
      "Cost after iteration 46200: 0.001444928115003977\n",
      "Cost after iteration 46300: 0.0014447678740892413\n",
      "Cost after iteration 46400: 0.0014446057249163375\n",
      "Cost after iteration 46500: 0.0014444450749251509\n",
      "Cost after iteration 46600: 0.001444283919708945\n",
      "Cost after iteration 46700: 0.0014441237040245074\n",
      "Cost after iteration 46800: 0.0014439627885708267\n",
      "Cost after iteration 46900: 0.0014438014391861278\n",
      "Cost after iteration 47000: 0.001443641203107864\n",
      "Cost after iteration 47100: 0.001443495304343308\n",
      "Cost after iteration 47200: 0.0014433504320465155\n",
      "Cost after iteration 47300: 0.0014432059808632519\n",
      "Cost after iteration 47400: 0.0014430614989356199\n",
      "Cost after iteration 47500: 0.0014429173109991103\n",
      "Cost after iteration 47600: 0.0014427723531195353\n",
      "Cost after iteration 47700: 0.0014426277708632978\n",
      "Cost after iteration 47800: 0.0014424834805016346\n",
      "Cost after iteration 47900: 0.0014423390872925525\n",
      "Cost after iteration 48000: 0.0014421941759103737\n",
      "Cost after iteration 48100: 0.001442063751549094\n",
      "Cost after iteration 48200: 0.0014419344750969238\n",
      "Cost after iteration 48300: 0.0014418041994859543\n",
      "Cost after iteration 48400: 0.0014416742381286591\n",
      "Cost after iteration 48500: 0.0014415451316096997\n",
      "Cost after iteration 48600: 0.0014414144473176515\n",
      "Cost after iteration 48700: 0.0014412844257136338\n",
      "Cost after iteration 48800: 0.0014411542909532806\n",
      "Cost after iteration 48900: 0.0014410244712120153\n",
      "Cost after iteration 49000: 0.001440894560621941\n",
      "Cost after iteration 49100: 0.0014407782340346308\n",
      "Cost after iteration 49200: 0.0014406609776761972\n",
      "Cost after iteration 49300: 0.001440543695964895\n",
      "Cost after iteration 49400: 0.0014404272392971114\n",
      "Cost after iteration 49500: 0.0014403105715891323\n",
      "Cost after iteration 49600: 0.0014401936449147184\n",
      "Cost after iteration 49700: 0.0014400771037432183\n",
      "Cost after iteration 49800: 0.0014399606375800594\n",
      "Cost after iteration 49900: 0.001439843558817877\n",
      "Cost after iteration 50000: 0.0014397270894887177\n",
      "Cost after iteration 50100: 0.0014396216348995646\n",
      "Cost after iteration 50200: 0.0014395168050012317\n",
      "Cost after iteration 50300: 0.0014394116609856638\n",
      "Cost after iteration 50400: 0.001439306808142759\n",
      "Cost after iteration 50500: 0.0014392019576111358\n",
      "Cost after iteration 50600: 0.0014390969229323056\n",
      "Cost after iteration 50700: 0.0014389921799668388\n",
      "Cost after iteration 50800: 0.0014388870538101694\n",
      "Cost after iteration 50900: 0.0014387825088341493\n",
      "Cost after iteration 51000: 0.001438677876607016\n",
      "Cost after iteration 51100: 0.0014385833163978762\n",
      "Cost after iteration 51200: 0.001438488518452967\n",
      "Cost after iteration 51300: 0.001438395058066675\n",
      "Cost after iteration 51400: 0.0014383001265735114\n",
      "Cost after iteration 51500: 0.0014382058723769687\n",
      "Cost after iteration 51600: 0.0014381113127564953\n",
      "Cost after iteration 51700: 0.0014380168627260521\n",
      "Cost after iteration 51800: 0.0014379228042723778\n",
      "Cost after iteration 51900: 0.0014378284129121428\n",
      "Cost after iteration 52000: 0.001437734345128945\n",
      "Cost after iteration 52100: 0.001437649275387095\n",
      "Cost after iteration 52200: 0.0014375645780554985\n",
      "Cost after iteration 52300: 0.0014374798630520478\n",
      "Cost after iteration 52400: 0.0014373947239906641\n",
      "Cost after iteration 52500: 0.001437310054018626\n",
      "Cost after iteration 52600: 0.001437225397347634\n",
      "Cost after iteration 52700: 0.00143714084349621\n",
      "Cost after iteration 52800: 0.001437055724035442\n",
      "Cost after iteration 52900: 0.0014369710515227503\n",
      "Cost after iteration 53000: 0.0014368863758146679\n",
      "Cost after iteration 53100: 0.0014368099052053638\n",
      "Cost after iteration 53200: 0.0014367337824630294\n",
      "Cost after iteration 53300: 0.0014366579607256724\n",
      "Cost after iteration 53400: 0.0014365816028900492\n",
      "Cost after iteration 53500: 0.0014365050403504368\n",
      "Cost after iteration 53600: 0.0014364293033137443\n",
      "Cost after iteration 53700: 0.0014363523031321874\n",
      "Cost after iteration 53800: 0.0014362760922077857\n",
      "Cost after iteration 53900: 0.0014362002538805345\n",
      "Cost after iteration 54000: 0.0014361236406533575\n",
      "Cost after iteration 54100: 0.001436055235313503\n",
      "Cost after iteration 54200: 0.0014359865474773993\n",
      "Cost after iteration 54300: 0.001435918015655256\n",
      "Cost after iteration 54400: 0.0014358494352170416\n",
      "Cost after iteration 54500: 0.0014357810885450618\n",
      "Cost after iteration 54600: 0.00143571261954707\n",
      "Cost after iteration 54700: 0.0014356439832692329\n",
      "Cost after iteration 54800: 0.0014355757264423602\n",
      "Cost after iteration 54900: 0.001435506857112254\n",
      "Cost after iteration 55000: 0.001435438250208903\n",
      "Cost after iteration 55100: 0.0014353766855685185\n",
      "Cost after iteration 55200: 0.0014353151236880409\n",
      "Cost after iteration 55300: 0.0014352530708434715\n",
      "Cost after iteration 55400: 0.0014351917055021762\n",
      "Cost after iteration 55500: 0.0014351300949275502\n",
      "Cost after iteration 55600: 0.001435068684146507\n",
      "Cost after iteration 55700: 0.0014350068058226015\n",
      "Cost after iteration 55800: 0.0014349452780339624\n",
      "Cost after iteration 55900: 0.001434883471666631\n",
      "Cost after iteration 56000: 0.0014348218162611487\n",
      "Cost after iteration 56100: 0.0014347662427937854\n",
      "Cost after iteration 56200: 0.0014347109466861022\n",
      "Cost after iteration 56300: 0.0014346554260356973\n",
      "Cost after iteration 56400: 0.0014346002214725912\n",
      "Cost after iteration 56500: 0.0014345446088142447\n",
      "Cost after iteration 56600: 0.0014344890489516016\n",
      "Cost after iteration 56700: 0.0014344336395924252\n",
      "Cost after iteration 56800: 0.0014343782319634788\n",
      "Cost after iteration 56900: 0.0014343233190804315\n",
      "Cost after iteration 57000: 0.0014342673405390817\n",
      "Cost after iteration 57100: 0.0014342174749812848\n",
      "Cost after iteration 57200: 0.0014341676211356634\n",
      "Cost after iteration 57300: 0.001434117756776793\n",
      "Cost after iteration 57400: 0.0014340677567185123\n",
      "Cost after iteration 57500: 0.0014340180545394366\n",
      "Cost after iteration 57600: 0.001433968096414034\n",
      "Cost after iteration 57700: 0.0014339183362124589\n",
      "Cost after iteration 57800: 0.0014338685614050017\n",
      "Cost after iteration 57900: 0.001433818927290511\n",
      "Cost after iteration 58000: 0.001433768862705217\n",
      "Cost after iteration 58100: 0.0014337239198412147\n",
      "Cost after iteration 58200: 0.0014336788473013687\n",
      "Cost after iteration 58300: 0.001433634284317367\n",
      "Cost after iteration 58400: 0.0014335893767213293\n",
      "Cost after iteration 58500: 0.0014335444283845788\n",
      "Cost after iteration 58600: 0.001433499987368421\n",
      "Cost after iteration 58700: 0.0014334548284367751\n",
      "Cost after iteration 58800: 0.0014334099566128545\n",
      "Cost after iteration 58900: 0.0014333651932317303\n",
      "Cost after iteration 59000: 0.0014333203884768593\n",
      "Cost after iteration 59100: 0.0014332798115107867\n",
      "Cost after iteration 59200: 0.0014332396701452197\n",
      "Cost after iteration 59300: 0.001433199176392396\n",
      "Cost after iteration 59400: 0.0014331589693253291\n",
      "Cost after iteration 59500: 0.0014331186775063463\n",
      "Cost after iteration 59600: 0.0014330783027420187\n",
      "Cost after iteration 59700: 0.0014330379186123197\n",
      "Cost after iteration 59800: 0.0014329974413213248\n",
      "Cost after iteration 59900: 0.0014329570965041893\n",
      "Cost after iteration 60000: 0.0014329171313683538\n",
      "Cost after iteration 60100: 0.0014328806511989375\n",
      "Cost after iteration 60200: 0.0014328441754300433\n",
      "Cost after iteration 60300: 0.0014328078607689179\n",
      "Cost after iteration 60400: 0.0014327715907005538\n",
      "Cost after iteration 60500: 0.0014327353741149925\n",
      "Cost after iteration 60600: 0.0014326990089304882\n",
      "Cost after iteration 60700: 0.0014326628616172492\n",
      "Cost after iteration 60800: 0.0014326264077655756\n",
      "Cost after iteration 60900: 0.0014325902050267504\n",
      "Cost after iteration 61000: 0.0014325539711363426\n",
      "Cost after iteration 61100: 0.0014325212120110183\n",
      "Cost after iteration 61200: 0.0014324885825028686\n",
      "Cost after iteration 61300: 0.001432455845876879\n",
      "Cost after iteration 61400: 0.0014324233526089144\n",
      "Cost after iteration 61500: 0.0014323906870735354\n",
      "Cost after iteration 61600: 0.001432358137210059\n",
      "Cost after iteration 61700: 0.0014323254276491682\n",
      "Cost after iteration 61800: 0.0014322928626545896\n",
      "Cost after iteration 61900: 0.0014322601095666642\n",
      "Cost after iteration 62000: 0.0014322275365006908\n",
      "Cost after iteration 62100: 0.001432198145284389\n",
      "Cost after iteration 62200: 0.001432168699671414\n",
      "Cost after iteration 62300: 0.0014321394934936177\n",
      "Cost after iteration 62400: 0.0014321098536499183\n",
      "Cost after iteration 62500: 0.0014320805959988033\n",
      "Cost after iteration 62600: 0.0014320512615177026\n",
      "Cost after iteration 62700: 0.0014320218127989223\n",
      "Cost after iteration 62800: 0.0014319924407827258\n",
      "Cost after iteration 62900: 0.0014319631108849359\n",
      "Cost after iteration 63000: 0.0014319337692052048\n",
      "Cost after iteration 63100: 0.0014319072584497434\n",
      "Cost after iteration 63200: 0.001431880830428832\n",
      "Cost after iteration 63300: 0.0014318544293433582\n",
      "Cost after iteration 63400: 0.0014318280412860959\n",
      "Cost after iteration 63500: 0.0014318016056983451\n",
      "Cost after iteration 63600: 0.0014317751618408592\n",
      "Cost after iteration 63700: 0.0014317488885139222\n",
      "Cost after iteration 63800: 0.0014317222689283209\n",
      "Cost after iteration 63900: 0.0014316959197414863\n",
      "Cost after iteration 64000: 0.001431669535526737\n",
      "Cost after iteration 64100: 0.001431645624016992\n",
      "Cost after iteration 64200: 0.0014316220116456625\n",
      "Cost after iteration 64300: 0.0014315981060383407\n",
      "Cost after iteration 64400: 0.0014315743712172866\n",
      "Cost after iteration 64500: 0.0014315505739447643\n",
      "Cost after iteration 64600: 0.0014315268050241257\n",
      "Cost after iteration 64700: 0.0014315030686595787\n",
      "Cost after iteration 64800: 0.0014314794105338932\n",
      "Cost after iteration 64900: 0.0014314555422438177\n",
      "Cost after iteration 65000: 0.0014314317153819537\n",
      "Cost after iteration 65100: 0.0014314103782552352\n",
      "Cost after iteration 65200: 0.0014313891197491155\n",
      "Cost after iteration 65300: 0.0014313676488426326\n",
      "Cost after iteration 65400: 0.0014313461590008114\n",
      "Cost after iteration 65500: 0.0014313247232550245\n",
      "Cost after iteration 65600: 0.0014313033470535713\n",
      "Cost after iteration 65700: 0.001431281914290955\n",
      "Cost after iteration 65800: 0.0014312605955909428\n",
      "Cost after iteration 65900: 0.0014312391729389055\n",
      "Cost after iteration 66000: 0.0014312177887728873\n",
      "Cost after iteration 66100: 0.0014311976752905374\n",
      "Cost after iteration 66200: 0.0014311775129402001\n",
      "Cost after iteration 66300: 0.0014311574269129915\n",
      "Cost after iteration 66400: 0.001431137271521563\n",
      "Cost after iteration 66500: 0.0014311171792905884\n",
      "Cost after iteration 66600: 0.0014310970411845732\n",
      "Cost after iteration 66700: 0.0014310767930537786\n",
      "Cost after iteration 66800: 0.001431056675536174\n",
      "Cost after iteration 66900: 0.0014310365404766568\n",
      "Cost after iteration 67000: 0.0014310163199115714\n",
      "Cost after iteration 67100: 0.0014309963441636777\n",
      "Cost after iteration 67200: 0.00143097607750909\n",
      "Cost after iteration 67300: 0.001430955868424267\n",
      "Cost after iteration 67400: 0.0014309358925811806\n",
      "Cost after iteration 67500: 0.0014309156106654022\n",
      "Cost after iteration 67600: 0.0014308954718281115\n",
      "Cost after iteration 67700: 0.0014308752910044543\n",
      "Cost after iteration 67800: 0.0014308551768672719\n",
      "Cost after iteration 67900: 0.001430835086164832\n",
      "Cost after iteration 68000: 0.0014308148844617912\n",
      "Cost after iteration 68100: 0.0014307947435761917\n",
      "Cost after iteration 68200: 0.001430774663624906\n",
      "Cost after iteration 68300: 0.0014307546331139456\n",
      "Cost after iteration 68400: 0.001430734270347164\n",
      "Cost after iteration 68500: 0.0014307141342017314\n",
      "Cost after iteration 68600: 0.0014306940015150907\n",
      "Cost after iteration 68700: 0.0014306739102537666\n",
      "Cost after iteration 68800: 0.0014306538790640028\n",
      "Cost after iteration 68900: 0.0014306337259215643\n",
      "Cost after iteration 69000: 0.001430613436511007\n",
      "Cost after iteration 69100: 0.0014305933072830093\n",
      "Cost after iteration 69200: 0.001430573216874018\n",
      "Cost after iteration 69300: 0.0014305530548816227\n",
      "Cost after iteration 69400: 0.0014305329684383445\n",
      "Cost after iteration 69500: 0.0014305128579803642\n",
      "Cost after iteration 69600: 0.0014304926638576605\n",
      "Cost after iteration 69700: 0.0014304726871773204\n",
      "Cost after iteration 69800: 0.001430452471583884\n",
      "Cost after iteration 69900: 0.0014304322503201864\n",
      "Cost after iteration 70000: 0.0014304121053420006\n",
      "Cost after iteration 70100: 0.0014303919710231413\n",
      "Cost after iteration 70200: 0.001430371975067109\n",
      "Cost after iteration 70300: 0.001430351864404846\n",
      "Cost after iteration 70400: 0.0014303315911542308\n",
      "Cost after iteration 70500: 0.0014303114404653615\n",
      "Cost after iteration 70600: 0.0014302914174515239\n",
      "Cost after iteration 70700: 0.001430271193701803\n",
      "Cost after iteration 70800: 0.001430251117141274\n",
      "Cost after iteration 70900: 0.0014302311375492623\n",
      "Cost after iteration 71000: 0.0014302110072828595\n",
      "Cost after iteration 71100: 0.0014301906914838958\n",
      "Cost after iteration 71200: 0.0014301705731581077\n",
      "Cost after iteration 71300: 0.0014301504756025056\n",
      "Cost after iteration 71400: 0.001430130360946323\n",
      "Cost after iteration 71500: 0.0014301102730597396\n",
      "Cost after iteration 71600: 0.0014300901749405902\n",
      "Cost after iteration 71700: 0.0014300701505579763\n",
      "Cost after iteration 71800: 0.0014300498289579512\n",
      "Cost after iteration 71900: 0.0014300297132462025\n",
      "Cost after iteration 72000: 0.0014300096205247478\n",
      "Cost after iteration 72100: 0.0014299894643641517\n",
      "Cost after iteration 72200: 0.00142996941469576\n",
      "Cost after iteration 72300: 0.0014299492709892126\n",
      "Cost after iteration 72400: 0.0014299291557040312\n",
      "Cost after iteration 72500: 0.00142990900934033\n",
      "Cost after iteration 72600: 0.0014298888336797492\n",
      "Cost after iteration 72700: 0.0014298688271886745\n",
      "Cost after iteration 72800: 0.0014298488099653607\n",
      "Cost after iteration 72900: 0.0014298285663021375\n",
      "Cost after iteration 73000: 0.0014298084203142904\n",
      "Cost after iteration 73100: 0.0014297883656470144\n",
      "Cost after iteration 73200: 0.001429768165136405\n",
      "Cost after iteration 73300: 0.0014297482596683003\n",
      "Cost after iteration 73400: 0.0014297279843746675\n",
      "Cost after iteration 73500: 0.001429707865225298\n",
      "Cost after iteration 73600: 0.001429687822815866\n",
      "Cost after iteration 73700: 0.001429667662848746\n",
      "Cost after iteration 73800: 0.0014296474954071758\n",
      "Cost after iteration 73900: 0.001429627465937068\n",
      "Cost after iteration 74000: 0.0014296073339946495\n",
      "Cost after iteration 74100: 0.0014295871647535012\n",
      "Cost after iteration 74200: 0.0014295670832303146\n",
      "Cost after iteration 74300: 0.0014295469707020466\n",
      "Cost after iteration 74400: 0.001429526857765412\n",
      "Cost after iteration 74500: 0.0014295067949154072\n",
      "Cost after iteration 74600: 0.0014294866649452098\n",
      "Cost after iteration 74700: 0.001429466505475527\n",
      "Cost after iteration 74800: 0.0014294463915785838\n",
      "Cost after iteration 74900: 0.0014294263031071931\n",
      "Cost after iteration 75000: 0.0014294062410014786\n",
      "Cost after iteration 75100: 0.0014293860775661494\n",
      "Cost after iteration 75200: 0.001429366104148842\n",
      "Cost after iteration 75300: 0.0014293459114645283\n",
      "Cost after iteration 75400: 0.0014293259123704623\n",
      "Cost after iteration 75500: 0.0014293056680557785\n",
      "Cost after iteration 75600: 0.0014292856061229413\n",
      "Cost after iteration 75700: 0.0014292655393163458\n",
      "Cost after iteration 75800: 0.001429245451634399\n",
      "Cost after iteration 75900: 0.001429225302548792\n",
      "Cost after iteration 76000: 0.0014292052466099536\n",
      "Cost after iteration 76100: 0.0014291850668028266\n",
      "Cost after iteration 76200: 0.0014291650556279476\n",
      "Cost after iteration 76300: 0.001429144841421726\n",
      "Cost after iteration 76400: 0.001429124764340744\n",
      "Cost after iteration 76500: 0.0014291047223676876\n",
      "Cost after iteration 76600: 0.0014290846382087519\n",
      "Cost after iteration 76700: 0.0014290645553502437\n",
      "Cost after iteration 76800: 0.001429044441455789\n",
      "Cost after iteration 76900: 0.0014290243415251\n",
      "Cost after iteration 77000: 0.0014290043308794736\n",
      "Cost after iteration 77100: 0.0014289840420156003\n",
      "Cost after iteration 77200: 0.0014289640024746138\n",
      "Cost after iteration 77300: 0.001428944098939092\n",
      "Cost after iteration 77400: 0.0014289238845092327\n",
      "Cost after iteration 77500: 0.0014289038943592794\n",
      "Cost after iteration 77600: 0.0014288836568073326\n",
      "Cost after iteration 77700: 0.0014288635061193414\n",
      "Cost after iteration 77800: 0.0014288434924297378\n",
      "Cost after iteration 77900: 0.0014288233857732168\n",
      "Cost after iteration 78000: 0.0014288033095579864\n",
      "Cost after iteration 78100: 0.001428783373735194\n",
      "Cost after iteration 78200: 0.0014287631832611571\n",
      "Cost after iteration 78300: 0.001428743020481493\n",
      "Cost after iteration 78400: 0.0014287229009746806\n",
      "Cost after iteration 78500: 0.0014287028253631294\n",
      "Cost after iteration 78600: 0.0014286827063782297\n",
      "Cost after iteration 78700: 0.0014286626793005245\n",
      "Cost after iteration 78800: 0.0014286426227015103\n",
      "Cost after iteration 78900: 0.001428622532729947\n",
      "Cost after iteration 79000: 0.00142860234492054\n",
      "Cost after iteration 79100: 0.0014285823059187299\n",
      "Cost after iteration 79200: 0.0014285624022436212\n",
      "Cost after iteration 79300: 0.0014285421890206029\n",
      "Cost after iteration 79400: 0.0014285220895282947\n",
      "Cost after iteration 79500: 0.0014285020156057128\n",
      "Cost after iteration 79600: 0.0014284819531125447\n",
      "Cost after iteration 79700: 0.0014284618507947491\n",
      "Cost after iteration 79800: 0.0014284417442620779\n",
      "Cost after iteration 79900: 0.0014284215959903788\n",
      "Cost after iteration 80000: 0.001428401572422474\n",
      "Cost after iteration 80100: 0.0014283814902569046\n",
      "Cost after iteration 80200: 0.0014283615077801824\n",
      "Cost after iteration 80300: 0.001428341397467061\n",
      "Cost after iteration 80400: 0.0014283212938743155\n",
      "Cost after iteration 80500: 0.001428301372433392\n",
      "Cost after iteration 80600: 0.0014282811909291004\n",
      "Cost after iteration 80700: 0.001428261025278239\n",
      "Cost after iteration 80800: 0.0014282410388775457\n",
      "Cost after iteration 80900: 0.0014282210073623448\n",
      "Cost after iteration 81000: 0.00142820082521253\n",
      "Cost after iteration 81100: 0.0014281807176856854\n",
      "Cost after iteration 81200: 0.001428160652232684\n",
      "Cost after iteration 81300: 0.0014281405972201605\n",
      "Cost after iteration 81400: 0.0014281205048881699\n",
      "Cost after iteration 81500: 0.0014281004866806362\n",
      "Cost after iteration 81600: 0.0014280803512050687\n",
      "Cost after iteration 81700: 0.0014280604672098982\n",
      "Cost after iteration 81800: 0.0014280402361493989\n",
      "Cost after iteration 81900: 0.0014280201693150079\n",
      "Cost after iteration 82000: 0.0014280001303471942\n",
      "Cost after iteration 82100: 0.0014279801511874698\n",
      "Cost after iteration 82200: 0.001427960041293145\n",
      "Cost after iteration 82300: 0.0014279398983362375\n",
      "Cost after iteration 82400: 0.001427919832466316\n",
      "Cost after iteration 82500: 0.0014278997522872026\n",
      "Cost after iteration 82600: 0.0014278796963170832\n",
      "Cost after iteration 82700: 0.0014278596672164816\n",
      "Cost after iteration 82800: 0.001427839590546309\n",
      "Cost after iteration 82900: 0.0014278196342188407\n",
      "Cost after iteration 83000: 0.001427799476074149\n",
      "Cost after iteration 83100: 0.001427779372228469\n",
      "Cost after iteration 83200: 0.0014277592951637697\n",
      "Cost after iteration 83300: 0.0014277392215046208\n",
      "Cost after iteration 83400: 0.0014277191943008664\n",
      "Cost after iteration 83500: 0.0014276991419380184\n",
      "Cost after iteration 83600: 0.0014276790597052347\n",
      "Cost after iteration 83700: 0.0014276589707791624\n",
      "Cost after iteration 83800: 0.0014276389883593466\n",
      "Cost after iteration 83900: 0.0014276188696420034\n",
      "Cost after iteration 84000: 0.0014275987935945442\n",
      "Cost after iteration 84100: 0.0014275787675930838\n",
      "Cost after iteration 84200: 0.0014275586398865864\n",
      "Cost after iteration 84300: 0.001427538587518741\n",
      "Cost after iteration 84400: 0.0014275185781609393\n",
      "Cost after iteration 84500: 0.0014274985540093678\n",
      "Cost after iteration 84600: 0.0014274784828863774\n",
      "Cost after iteration 84700: 0.0014274584519359745\n",
      "Cost after iteration 84800: 0.0014274383591164606\n",
      "Cost after iteration 84900: 0.0014274184157105465\n",
      "Cost after iteration 85000: 0.001427398284376914\n",
      "Cost after iteration 85100: 0.0014273781536473826\n",
      "Cost after iteration 85200: 0.0014273582166320473\n",
      "Cost after iteration 85300: 0.0014273381441297914\n",
      "Cost after iteration 85400: 0.001427318090252147\n",
      "Cost after iteration 85500: 0.0014272979534065476\n",
      "Cost after iteration 85600: 0.001427277907445498\n",
      "Cost after iteration 85700: 0.0014272579120329298\n",
      "Cost after iteration 85800: 0.001427237841487384\n",
      "Cost after iteration 85900: 0.0014272178065074222\n",
      "Cost after iteration 86000: 0.0014271977512721214\n",
      "Cost after iteration 86100: 0.0014271777184196798\n",
      "Cost after iteration 86200: 0.0014271576338430658\n",
      "Cost after iteration 86300: 0.0014271375590444823\n",
      "Cost after iteration 86400: 0.0014271175976140274\n",
      "Cost after iteration 86500: 0.0014270975294845677\n",
      "Cost after iteration 86600: 0.0014270774676610578\n",
      "Cost after iteration 86700: 0.0014270573730023157\n",
      "Cost after iteration 86800: 0.0014270373704288496\n",
      "Cost after iteration 86900: 0.0014270173106755081\n",
      "Cost after iteration 87000: 0.0014269972376284084\n",
      "Cost after iteration 87100: 0.00142697723030165\n",
      "Cost after iteration 87200: 0.0014269572880837725\n",
      "Cost after iteration 87300: 0.0014269371500428604\n",
      "Cost after iteration 87400: 0.0014269170941200468\n",
      "Cost after iteration 87500: 0.0014268972639737607\n",
      "Cost after iteration 87600: 0.001426877161450706\n",
      "Cost after iteration 87700: 0.0014268569218705627\n",
      "Cost after iteration 87800: 0.0014268368746197867\n",
      "Cost after iteration 87900: 0.0014268168769063728\n",
      "Cost after iteration 88000: 0.0014267968293669336\n",
      "Cost after iteration 88100: 0.0014267768653487374\n",
      "Cost after iteration 88200: 0.0014267568315303322\n",
      "Cost after iteration 88300: 0.0014267367638186926\n",
      "Cost after iteration 88400: 0.0014267167400565345\n",
      "Cost after iteration 88500: 0.0014266968592837209\n",
      "Cost after iteration 88600: 0.0014266766791170328\n",
      "Cost after iteration 88700: 0.0014266566497816888\n",
      "Cost after iteration 88800: 0.001426636553398785\n",
      "Cost after iteration 88900: 0.0014266165445275807\n",
      "Cost after iteration 89000: 0.0014265965364567805\n",
      "Cost after iteration 89100: 0.0014265764750547214\n",
      "Cost after iteration 89200: 0.001426556487966283\n",
      "Cost after iteration 89300: 0.0014265364225508866\n",
      "Cost after iteration 89400: 0.0014265163631847454\n",
      "Cost after iteration 89500: 0.0014264964159430443\n",
      "Cost after iteration 89600: 0.0014264762647190645\n",
      "Cost after iteration 89700: 0.0014264563172237444\n",
      "Cost after iteration 89800: 0.0014264362764946571\n",
      "Cost after iteration 89900: 0.0014264162163426094\n",
      "Cost after iteration 90000: 0.0014263963522453769\n",
      "Cost after iteration 90100: 0.0014263761369016944\n",
      "Cost after iteration 90200: 0.0014263561669868854\n",
      "Cost after iteration 90300: 0.0014263361403442534\n",
      "Cost after iteration 90400: 0.001426316127204719\n",
      "Cost after iteration 90500: 0.0014262960321783603\n",
      "Cost after iteration 90600: 0.0014262760304348063\n",
      "Cost after iteration 90700: 0.0014262561336215284\n",
      "Cost after iteration 90800: 0.0014262359683085257\n",
      "Cost after iteration 90900: 0.0014262159959183473\n",
      "Cost after iteration 91000: 0.0014261959997474236\n",
      "Cost after iteration 91100: 0.0014261759378860655\n",
      "Cost after iteration 91200: 0.0014261558724575924\n",
      "Cost after iteration 91300: 0.001426135850295266\n",
      "Cost after iteration 91400: 0.0014261158733067838\n",
      "Cost after iteration 91500: 0.001426095918677517\n",
      "Cost after iteration 91600: 0.0014260758078438042\n",
      "Cost after iteration 91700: 0.0014260558003551293\n",
      "Cost after iteration 91800: 0.001426035845158955\n",
      "Cost after iteration 91900: 0.0014260157936527846\n",
      "Cost after iteration 92000: 0.001425995743966371\n",
      "Cost after iteration 92100: 0.001425975753065791\n",
      "Cost after iteration 92200: 0.001425955621757138\n",
      "Cost after iteration 92300: 0.0014259357311249925\n",
      "Cost after iteration 92400: 0.0014259157129096589\n",
      "Cost after iteration 92500: 0.001425895582011043\n",
      "Cost after iteration 92600: 0.0014258755810702686\n",
      "Cost after iteration 92700: 0.0014258556594070426\n",
      "Cost after iteration 92800: 0.0014258356247432921\n",
      "Cost after iteration 92900: 0.0014258155595795045\n",
      "Cost after iteration 93000: 0.0014257955493717132\n",
      "Cost after iteration 93100: 0.001425775546384085\n",
      "Cost after iteration 93200: 0.001425755530824446\n",
      "Cost after iteration 93300: 0.0014257354865460745\n",
      "Cost after iteration 93400: 0.0014257155666301227\n",
      "Cost after iteration 93500: 0.001425695649778061\n",
      "Cost after iteration 93600: 0.0014256755714861335\n",
      "Cost after iteration 93700: 0.0014256556185599238\n",
      "Cost after iteration 93800: 0.0014256354927444275\n",
      "Cost after iteration 93900: 0.0014256154675933812\n",
      "Cost after iteration 94000: 0.0014255954957679538\n",
      "Cost after iteration 94100: 0.0014255756201300433\n",
      "Cost after iteration 94200: 0.0014255554810327581\n",
      "Cost after iteration 94300: 0.0014255355352248368\n",
      "Cost after iteration 94400: 0.0014255154397315218\n",
      "Cost after iteration 94500: 0.0014254954477356454\n",
      "Cost after iteration 94600: 0.001425475403501405\n",
      "Cost after iteration 94700: 0.0014254554501375888\n",
      "Cost after iteration 94800: 0.0014254354024485977\n",
      "Cost after iteration 94900: 0.0014254154145144054\n",
      "Cost after iteration 95000: 0.0014253954051183508\n",
      "Cost after iteration 95100: 0.00142537541754261\n",
      "Cost after iteration 95200: 0.0014253554329620578\n",
      "Cost after iteration 95300: 0.0014253354966724222\n",
      "Cost after iteration 95400: 0.0014253154169121996\n",
      "Cost after iteration 95500: 0.0014252954409257575\n",
      "Cost after iteration 95600: 0.001425275496101332\n",
      "Cost after iteration 95700: 0.0014252554966750893\n",
      "Cost after iteration 95800: 0.0014252354488677422\n",
      "Cost after iteration 95900: 0.0014252154509935707\n",
      "Cost after iteration 96000: 0.0014251955633832003\n",
      "Cost after iteration 96100: 0.0014251754462174897\n",
      "Cost after iteration 96200: 0.0014251554765269902\n",
      "Cost after iteration 96300: 0.001425135425842658\n",
      "Cost after iteration 96400: 0.0014251154681485221\n",
      "Cost after iteration 96500: 0.0014250955663501629\n",
      "Cost after iteration 96600: 0.0014250754773532542\n",
      "Cost after iteration 96700: 0.0014250555802166089\n",
      "Cost after iteration 96800: 0.001425035659836468\n",
      "Cost after iteration 96900: 0.0014250154500098059\n",
      "Cost after iteration 97000: 0.0014249956056559042\n",
      "Cost after iteration 97100: 0.0014249755910456607\n",
      "Cost after iteration 97200: 0.001424955612893099\n",
      "Cost after iteration 97300: 0.0014249355025082997\n",
      "Cost after iteration 97400: 0.001424915543221695\n",
      "Cost after iteration 97500: 0.0014248955381881308\n",
      "Cost after iteration 97600: 0.0014248754920439606\n",
      "Cost after iteration 97700: 0.0014248555906882434\n",
      "Cost after iteration 97800: 0.001424835572160361\n",
      "Cost after iteration 97900: 0.0014248155767084363\n",
      "Cost after iteration 98000: 0.0014247956462483755\n",
      "Cost after iteration 98100: 0.0014247755651430368\n",
      "Cost after iteration 98200: 0.0014247556177843738\n",
      "Cost after iteration 98300: 0.0014247356532619039\n",
      "Cost after iteration 98400: 0.001424715751336263\n",
      "Cost after iteration 98500: 0.001424695627935439\n",
      "Cost after iteration 98600: 0.0014246756662741103\n",
      "Cost after iteration 98700: 0.0014246556839967216\n",
      "Cost after iteration 98800: 0.0014246357671674507\n",
      "Cost after iteration 98900: 0.0014246157995168901\n",
      "Cost after iteration 99000: 0.0014245957186709715\n",
      "Cost after iteration 99100: 0.0014245757585993148\n",
      "Cost after iteration 99200: 0.0014245558613839929\n",
      "Cost after iteration 99300: 0.0014245357386986216\n",
      "Cost after iteration 99400: 0.0014245158785267116\n",
      "Cost after iteration 99500: 0.0014244959941414597\n",
      "Cost after iteration 99600: 0.0014244758986255363\n",
      "Cost after iteration 99700: 0.001424455902411579\n",
      "Cost after iteration 99800: 0.0014244358537308006\n",
      "Cost after iteration 99900: 0.001424415926287376\n",
      "Cost after iteration 100000: 0.0014243960992042514\n"
     ]
    }
   ],
   "source": [
    "parameters, costs = dnn_model(X=train_set_x,\n",
    "                                  Y=train_set_y_orig,\n",
    "                                  layers_dims=[12288, 32, 1],\n",
    "                                  learning_rate=0.01,\n",
    "                                  num_iterations=100_000,\n",
    "                                  print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 100.0\n",
      "test accuracy: 76.0\n"
     ]
    }
   ],
   "source": [
    "train_predictions = predict(parameters, train_set_x)\n",
    "test_predictions = predict(parameters, test_set_x)\n",
    "train_acc = 100 - np.mean(np.abs(train_predictions - train_set_y_orig)) * 100\n",
    "test_acc = 100 - np.mean(np.abs(test_predictions - test_set_y_orig)) * 100\n",
    "print(f\"train accuracy: {train_acc}\")\n",
    "print(f\"test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
